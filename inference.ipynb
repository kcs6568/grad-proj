{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from matplotlib.image import _ImageBase\n",
    "from matplotlib.style import available\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "from PIL import Image\n",
    "from cv2 import transform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as tv_F\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "from lib.utils.parser import InferenceParser\n",
    "from lib.model_api.build_model import build_model\n",
    "\n",
    "\n",
    "'''\n",
    "automobile = car\n",
    "\n",
    "'''\n",
    "\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "stl_classes = ['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']\n",
    "\n",
    "# 91 classes\n",
    "coco_classes_91 = (\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella',\n",
    "    'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', \n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window',\n",
    "    'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush'\n",
    ")\n",
    "\n",
    "coco_classes_80 = (\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', \n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table',\n",
    "    'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    ")\n",
    "\n",
    "voc_classes = ('background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car',\n",
    "               'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train',\n",
    "               'tvmonitor')\n",
    "\n",
    "VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "\n",
    "def visualize_classification(prediction, output_dir, save_name):\n",
    "    results = F.softmax(prediction['outputs'], dim=1)\n",
    "    print(results)\n",
    "    if isinstance(results, torch.Tensor):\n",
    "        results = results.cpu().detach().numpy()\n",
    "        \n",
    "    cmap = plt.cm.YlGn\n",
    "    # norm = colors.Normalize(vmin=1.5, vmax=4.5)\n",
    "    # c = np.random.rand(len(results))*3+1.5\n",
    "    \n",
    "    im = plt.imshow(results.reshape(1, 10), cmap=cmap)\n",
    "    plt.xticks(np.arange(10), labels=cifar_classes, rotation=90, fontsize=23)\n",
    "    ax = plt.gca()\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    # create an axes on the right side of ax. The width of cax will be 5%\n",
    "    # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    \n",
    "    plt.colorbar(im, cax)\n",
    "    plt.show()    \n",
    "    plt.savefig(\n",
    "        os.path.join(output_dir, f\"{save_name}_prob.png\"),\n",
    "        dpi=600)\n",
    "    \n",
    "\n",
    "def visualize_detection(image, prediction, output_dir, save_name):\n",
    "    def _nms(scores, threshold=0.8):\n",
    "        available_idx = np.ndarray(scores.shape)\n",
    "        \n",
    "        for i, s in enumerate(scores):\n",
    "            if s >= threshold:\n",
    "                available_idx[i] = 1\n",
    "            else:\n",
    "                available_idx[i] = 0\n",
    "                \n",
    "        return available_idx\n",
    "    \n",
    "    \n",
    "    from torchvision.utils import draw_bounding_boxes, save_image\n",
    "    \n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    boxes = prediction[0]['boxes'].cpu().detach().numpy()\n",
    "    scores = prediction[0]['scores'].cpu().detach().numpy()\n",
    "    labels = prediction[0]['labels'].cpu().detach().numpy()\n",
    "    boxes = boxes.astype(np.int32)\n",
    "    \n",
    "    available_boxes_idx = _nms(prediction[0]['scores'])\n",
    "    \n",
    "    # boxes = prediction[0]['boxes'].to(torch.uint8)\n",
    "    # labels = [str(l.cpu().detach()) for l in prediction['labels']]\n",
    "    \n",
    "    color = [\n",
    "        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 255), (36,255,12)\n",
    "    ]\n",
    "    \n",
    "    font = [\n",
    "        cv2.FONT_ITALIC,\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_TRIPLEX\n",
    "    ]\n",
    "    \n",
    "    print(prediction)\n",
    "    # exit()\n",
    "    for i, (xmin, ymin, xmax, ymax) in enumerate(boxes):\n",
    "        if available_boxes_idx[i] == 1:\n",
    "            # print(boxes[i], scores[i], labels[i], coco_classes_91[labels[i]-1])\n",
    "            image = cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color[-1], 1)\n",
    "            \n",
    "            label = coco_classes_91[labels[i]-1]\n",
    "            score = str(round(scores[i], 2))\n",
    "            text = f\"{label}|{score}\"\n",
    "            print(i, labels[i], label, score)\n",
    "            print(text)\n",
    "            cv2.putText(image, text, (xmin, ymin-10), font[1], 0.5, color[-2], 1)\n",
    "    # exit()\n",
    "    save_path = os.path.join(output_dir, f\"{save_name}.png\")\n",
    "    cv2.imwrite(save_path, image)\n",
    "    \n",
    "    # drawn_boxes = draw_bounding_boxes(\n",
    "    #     image, \n",
    "    #     boxes,\n",
    "    #     fill=True)\n",
    "    #     # labels)\n",
    "    \n",
    "    # print(drawn_boxes)\n",
    "    # print(drawn_boxes.size())\n",
    "    \n",
    "    # drawn_boxes = drawn_boxes.permute(2, 1, 0)\n",
    "    # print(drawn_boxes.size())\n",
    "    # drawn_boxes = drawn_boxes.cpu().detach().numpy()\n",
    "    # save_path = os.path.join(output_dir, f\"{save_name}_drawn.png\")\n",
    "    # plt.imshow(drawn_boxes)\n",
    "    # plt.savefig(\n",
    "    #     save_path, dpi=600\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # save_image(drawn_boxes, save_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    # fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = tv_F.to_pil_image(img)\n",
    "        plt.imshow(np.asarray(img))\n",
    "        plt.axis(\"off\")\n",
    "        plt.savefig(f\"/root/test{i}.png\")\n",
    "        \n",
    "        # axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        # exit()\n",
    "        \n",
    "\n",
    "\n",
    "def visualize_segmentation(image, torch_image, prediction, output_dir, save_name, threshold=0.8):\n",
    "    from torchvision.utils import draw_segmentation_masks, save_image\n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    prediction = prediction['outputs']\n",
    "    print(prediction.size())\n",
    "    \n",
    "    masks = torch.nn.functional.softmax(prediction, dim=1)\n",
    "    m = masks[0].cpu().detach().numpy()\n",
    "    \n",
    "    # image_copy_for_mask = deepcopy(image)\n",
    "    for i, c in enumerate(VOC_COLORMAP):\n",
    "        image_copy = deepcopy(image)\n",
    "        image_copy_for_mask = deepcopy(image)\n",
    "        m_ = cv2.threshold(m[i], 0.3, 255, cv2.THRESH_BINARY)[1]\n",
    "        image_copy_for_mask[m_==255] = c\n",
    "        # transparented_result = cv2.addWeighted(image_copy, 0.5, image_copy_for_mask, 0.7, 0)\n",
    "    # bool_masks = [m > threshold for m in masks[0]]\n",
    "    \n",
    "        cv2.imwrite(f\"/root/volume/seg_multi_res_{i}.png\", image_copy_for_mask)\n",
    "    \n",
    "    # # mask = bool_masks[0].cpu().detach().numpy()\n",
    "    # mask = masks[0][0].cpu().detach().numpy()\n",
    "    # dst = cv2.addWeighted(image, 0.8, mask, 0.2, 0)\n",
    "    \n",
    "    # cv2.imwrite(\"ttt.png\", dst)\n",
    "    exit()\n",
    "    \n",
    "    \n",
    "    # result = [m for m in masks[0]]\n",
    "    # print(result[0].unsqueeze(0).size())\n",
    "    # exit()\n",
    "    # show(result)\n",
    "    # exit()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # masks = torch.nn.functional.softmax(prediction, dim=1)\n",
    "    # print(masks.size())\n",
    "    # exit()\n",
    "\n",
    "    # torch_image = torch_image.to(torch.uint8)\n",
    "    \n",
    "    \n",
    "    # re = prediction.argmax(1).flatten()\n",
    "    # print(re.size())\n",
    "    # exit()\n",
    "    \n",
    "    \n",
    "    # a = masks[0][0][0]\n",
    "    # print(a.size())\n",
    "    # for p in masks:\n",
    "    #     print(p)\n",
    "    exit()\n",
    "    \n",
    "    \n",
    "    cls = torch.argmax(prediction, dim=1)\n",
    "    print(cls.size())\n",
    "    print(max(cls))\n",
    "    exit()\n",
    "    \n",
    "    \n",
    "    \n",
    "    cls = cls.to(torch.uint8)\n",
    "    a = draw_segmentation_masks(torch_image[0], cls)\n",
    "    exit()\n",
    "    \n",
    "    image = np.array(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    prediction = prediction['outputs']\n",
    "    cls = torch.argmax(prediction, dim=1)\n",
    "    cls = cls.cpu().detach().numpy()\n",
    "    # canvus = np.zeros(cls.shape, np.uint8)\n",
    "    \n",
    "    cv2.imwrite(\"./test.png\", cls)\n",
    "    \n",
    "    # print(cls)\n",
    "    prediction = prediction.cpu().detach().numpy()\n",
    "    pred_imgs = [prediction[p] for p in cls]\n",
    "\n",
    "    print(pred_imgs)\n",
    "    print(pred_imgs.shape)\n",
    "    \n",
    "    # for i, pred_img in enumerate(pred_imgs):\n",
    "    #     plt.imshow(pred_img)\n",
    "    #     plt.savefig(\n",
    "    #         f\"./test_{i}\", dpi=600\n",
    "    #     )\n",
    "    \n",
    "    exit()\n",
    "    \n",
    "    \n",
    "    masks = torch.nn.functional.softmax(prediction, dim=1)\n",
    "    \n",
    "    \n",
    "    bool_masks = masks > threshold\n",
    "    # bool_masks = bool_masks.permute(2, 1, 0)\n",
    "    # print(bool_masks.size())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return\n",
    "    color = [\n",
    "        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 255), (36,255,12)\n",
    "    ]\n",
    "    \n",
    "    font = [\n",
    "        cv2.FONT_ITALIC,\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_TRIPLEX\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    save_path = os.path.join(output_dir, f\"{save_name}.png\")\n",
    "    cv2.imwrite(save_path, image)\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    with open(args.yaml_cfg, 'r') as f:\n",
    "        configs = yaml.safe_load(f)\n",
    "    \n",
    "    for i, j in configs.items():\n",
    "        setattr(args, i, j)\n",
    "        \n",
    "    with open(args.cfg, 'r') as f:\n",
    "        configs = yaml.safe_load(f)\n",
    "    \n",
    "    for i, j in configs.items():\n",
    "        setattr(args, i, j)\n",
    "    \n",
    "    model = build_model(args)\n",
    "    ckpt = os.path.join(args.ckpt)\n",
    "    checkpoint = torch.load(ckpt, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    best_result = checkpoint['best_results']\n",
    "    print(\"best result:\", best_result)\n",
    "    \n",
    "    torch.cuda.set_device(int(args.gpu))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    images = [\n",
    "        Image.open(args.det_sample),\n",
    "        Image.open(args.seg_sample)\n",
    "    ]\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        infer_transform = transforms.Compose([transforms.ToTensor()])\n",
    "        torch_image = infer_transform(image).unsqueeze(0).cuda()\n",
    "        \n",
    "        task_cfg = args.task[args.task_type]\n",
    "        prediction = model(torch_image, task_cfg)\n",
    "        \n",
    "        dataset = list(task_cfg.keys())[0]\n",
    "        task = list(task_cfg.values())[0]\n",
    "        \n",
    "        save_name = args.save_name + f\"_{str(i)}\"\n",
    "        \n",
    "        if task == 'clf':\n",
    "            visualize_classification(prediction, args.outdir, save_name)\n",
    "        elif task == 'det':\n",
    "            visualize_detection(image, prediction, args.outdir, save_name)\n",
    "        elif task == 'seg':\n",
    "            visualize_segmentation(image, torch_image, prediction, args.outdir, save_name)\n",
    "    \n",
    "    print(\"Inference Finish\\n\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = InferenceParser().args\n",
    "    main(args)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # x = np.arange(10)\n",
    "    # y = np.random.rand(len(x))\n",
    "    # c = np.random.rand(len(x))*3+1.5\n",
    "    # df = pd.DataFrame({\"x\":x,\"y\":y,\"c\":c})\n",
    "\n",
    "    # cmap = plt.cm.YlGn\n",
    "    # norm = colors.Normalize(vmin=1.5, vmax=4.5)\n",
    "\n",
    "    # # plt.barh(y, x, color=cmap(norm(df.c.values)))\n",
    "    \n",
    "    # # plt.yticks([0, 0.5, 1])\n",
    "    # # plt.xticks(['a', 'b', 'c','d','e','f','g','h','i','j'])\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "    # hbars = ax.barh(y, x, color=cmap(norm(c)))\n",
    "    # # ax.set_xticks([0, 0.5, 1])\n",
    "    # ax.set_yticks(y, labels=classes)\n",
    "    # ax.invert_yaxis()\n",
    "    # ax.set_xlim(right=1)\n",
    "\n",
    "    # # \n",
    "    # sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # sm.set_array([])  # only needed for matplotlib < 3.1\n",
    "    # fig.colorbar(sm)\n",
    "\n",
    "\n",
    "    # cmap = plt.cm.YlGn\n",
    "    # norm = colors.Normalize(vmin=1.5, vmax=4.5)\n",
    "    # people = classes\n",
    "    # y_pos = np.arange(len(people))\n",
    "    # c = np.random.rand(len(people))*3+1.5\n",
    "    # performance = np.array([9.9990e-01, 3.2414e-10, 8.3237e-05, 2.4076e-06, 5.4104e-08, 4.2238e-09,\n",
    "    #      1.4520e-08, 1.2475e-10, 1.9153e-05, 7.9884e-10])\n",
    "    \n",
    "    # fig, ax = plt.subplots()\n",
    "\n",
    "    # hbars = ax.barh(y_pos, performance, align='center', color=cmap(norm(c)))\n",
    "    # ax.set_yticks(y_pos, labels=people)\n",
    "    # ax.invert_yaxis()  # labels read top-to-bottom\n",
    "    # ax.set_xlabel('Performance')\n",
    "    # ax.set_xticks([0, 0.5, 1])\n",
    "    # ax.set_title('How fast do you want to go today?')\n",
    "\n",
    "    # # Label with specially formatted floats\n",
    "    # # ax.bar_label(hbars, fmt='%.2f')\n",
    "    # ax.set_xlim(right=0.1)  # adjust xlim to fit labels\n",
    "\n",
    "\n",
    "    # c = ax1.pcolor(Z, edgecolors='k', linewidths=4)\n",
    "    # ax1.set_title('thick edges')\n",
    "\n",
    "    \n",
    "    \n",
    "    # color = [192, 64, 1]\n",
    "    # ratio = np.array([1/3, 1/2, 1/1, 1/5, 1/7, 1/8, 1/2, 1/2, 1/1, 1/3])\n",
    "    \n",
    "    # r, g, b = 192, 64, 1\n",
    "    # r, g, b = [x/255.0 for x in [r, g, b]]\n",
    "    # h, l, s = colorsys.rgb_to_hls(r, g*1/3, b)\n",
    "    # r, g, b = colorsys.hls_to_rgb(h, l, s)\n",
    "    # r, g, b = [x*255.0 for x in [r, g, b]]\n",
    "    \n",
    "    # print(r, g, b)\n",
    "    # exit()\n",
    "    \n",
    "    \n",
    "    # data = [scale_lightness(color, 1/scale) for scale in ratio]\n",
    "    # print(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # # exit()\n",
    "    \n",
    "    \n",
    "    # # rgb_ratio = colors.hsv_to_rgb(hsv_ratio)\n",
    "    # # print(rgb_ratio)\n",
    "    # # # print(hsv_ratio)\n",
    "    # # exit()\n",
    "    # # colors = [255, 255, 0]\n",
    "    \n",
    "    # # data = (np.array(ratio) * 60).round().astype(int)\n",
    "    # ratios_int = (np.array(ratio) * 60).round().astype(int)\n",
    "    # plt.imshow(\n",
    "    #     np.repeat(np.arange(len(data)), ratios_int).reshape(1, -1),\n",
    "    #     cmap=colors.ListedColormap(data),\n",
    "    #     aspect=ratios_int.sum()/10\n",
    "    # )\n",
    "    \n",
    "    # plt.axis('off')\n",
    "    \n",
    "    \n",
    "    # ax = plt.subplots()\n",
    "    # im = ax.imshow(np.array(10).reshape(1,10), cmap=)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
